{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "REDWINE_PATH = \"../datasets/winequality-red.csv\"\n",
    "WHITEWINE_PATH = \"../datasets/winequality-white.csv\"\n",
    "\n",
    "# read red wine set of observations\n",
    "data_red = pd.read_csv(REDWINE_PATH,sep=',')\n",
    "data_red['color'] = 1 #redwine\n",
    "\n",
    "print(data_red.shape)\n",
    "\n",
    "# read white wine set of observations\n",
    "data_white = pd.read_csv(WHITEWINE_PATH,sep=',')\n",
    "data_white['color'] = 0 #whitewine\n",
    "\n",
    "print(data_white.shape)\n",
    "\n",
    "# merge the two sets in one\n",
    "data = data_red.merge(data_white, how='outer')\n",
    "fields = list(data.columns)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#sns.pairplot(data, diag_kind='hist',hue='color')\n",
    "#sns.pairplot(data)\n",
    "\n",
    "# show the histograms of values per feature (eg most of whines are at about 8 proof strength)\n",
    "sns.set()\n",
    "data.hist(figsize=(10,10),color='red', bins=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the historgram of wine rankings (quality between 1 and 10)\n",
    "data['quality'].hist(color='red', bins=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's try to find the most important features by using PCA\n",
    "# first off drop off the non-chemical features.\n",
    "data = data.drop(columns=['color','quality'])\n",
    "fields = list(data.columns)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "\n",
    "X = data[fields]\n",
    "X = scale(X)\n",
    "\n",
    "pca = PCA(n_components=11)\n",
    "\n",
    "pca.fit(X)\n",
    "\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "print(var1)\n",
    "plt.plot(var1)\n",
    "\n",
    "pca = PCA(n_components=9)\n",
    "pca.fit(X)\n",
    "X1=pca.fit_transform(X)\n",
    "\n",
    "#print(X1)\n",
    "\n",
    "# the component with the lowest contribution is at 28% whihc is still significant to be dropped off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_red = pd.read_csv(REDWINE_PATH,sep=',')\n",
    "data_red['color'] = 1 #redwine\n",
    "\n",
    "print(data_red.shape)\n",
    "\n",
    "data_white = pd.read_csv(WHITEWINE_PATH,sep=',')\n",
    "data_white['color'] = 0 #whitewine\n",
    "\n",
    "print(data_white.shape)\n",
    "\n",
    "data = data_red.merge(data_white, how='outer')\n",
    "\n",
    "\n",
    "# based on the \"quality histograms\" above, we will drop the ratings with low counts (we will keep only 5,6,7)\n",
    "data = data.drop(data[data.quality == 1].index)    # not recorded anyway\n",
    "data = data.drop(data[data.quality == 2].index)    # not recorded anyway\n",
    "data = data.drop(data[data.quality == 10].index)   # not recorded anyway\n",
    "data = data.drop(data[data.quality == 9].index)\n",
    "data = data.drop(data[data.quality == 3].index)\n",
    "data = data.drop(data[data.quality == 8].index)\n",
    "data = data.drop(data[data.quality == 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = list(data.columns)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set in two: 1) color+features (observations)  2) quality (actuals)\n",
    "\n",
    "fields = list(data.columns[:-2])\n",
    "fields.append('color')  #adding color back\n",
    "X = data[fields]\n",
    "y = data['quality']\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pearson correlation was used to identify which features correlate with wine quality. It looks as if higher the alcohol content the higher the quality. Lower density and volatile acidity also correlated with better quality as seen in the pairwise correlation chart the chart below. Only the top 5 correlated features were carried over to the SVM models."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data[fields].corrwith(y)\n",
    "correlations.sort_values(inplace=True)\n",
    "\n",
    "# the following fields are the 5 retained as having the highest correlations to wine quality\n",
    "fields = correlations.map(abs).sort_values().iloc[-5:].index\n",
    "print(fields) #prints the top two abs correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# The figure below shows Pearson Pairwise correlation of features to wine quality.\n",
    "# Looks like alcohol and density are the most correlated with quality\n",
    "ax = correlations.plot(kind='bar')\n",
    "ax.set(ylim=[-1, 1], ylabel='pearson correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = data[fields]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\n",
    "print(X.columns) #scaled columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run now Support Vector Machines (SVM) to create a \"prediction model\"\n",
    "\n",
    "SVM converges faster when features are scaled. If the model is senstive to magnitudes its generally a good idea to scale so one feature doesn’t get more influence than the other(in terms of scale)."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# we will split the data in training (70%) and testing (30%) whihc is the usual ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GridSearchCV to tune hyperparameters for the SVM.\n",
    "\n",
    "A Machine Learning model is defined as a mathematical model with a number of parameters that need to be learned from the data. However, there are some parameters, known as Hyperparameters and those cannot be directly learned. They are commonly chosen by human based on some intuition or hit and trial before the actual training begins. These parameters exhibits their importance by improving performance of the model such as its complexity or its learning rate. Models can have many hyper-parameters and finding the best combination of parameters can be treated as a search problem.\n",
    "\n",
    "SVM also has some hyper-parameters (like what C or gamma values to use) and finding optimal hyper-parameter is a very hard task to solve. But it can be found by just trying all combinations and see what parameters work best. The main idea behind it is to create a grid of hyper-parameters and just try all of their combinations (hence, this method is called Gridsearch, But don’t worry! we don’t have to do it manually because Scikit-learn has this functionality built-in with GridSearchCV.\n",
    "\n",
    "GridSearchCV takes a dictionary that describes the parameters that could be tried on a model to train it. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[.1, 1, 10], 'gamma':[.5, 1, 2, 10]}\n",
    "\n",
    "startproc = time.time()\n",
    "\n",
    "SVC_Gaussian = svm.SVC(gamma='scale')\n",
    "gscv = GridSearchCV(SVC_Gaussian, param_grid=parameters, cv=5)\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best parameters.\n",
    "\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above parameters to train the SVM model\n",
    "\n",
    "SVC_Gaussian = svm.SVC(kernel='rbf', gamma=10, C=1)\n",
    "SVC_Gaussian.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the wine rankings for the test data set\n",
    "\n",
    "y_pred = SVC_Gaussian.predict(X_test)\n",
    "\n",
    "proctime = time.time() - startproc\n",
    "\n",
    "print(y_pred,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Calculate the accuracy of prediction\n",
    "metrics = list()\n",
    "cm = dict()\n",
    "\n",
    "# Precision, recall, f-score from the multi-class support function\n",
    "precision, recall, fscore, _ = score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# The usual way to calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "metrics.append(pd.Series({'precision':precision, 'recall':recall, \n",
    "                          'fscore':fscore, 'accuracy':accuracy}, \n",
    "                         name='Model'))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVC_Gaussian.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Last, the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#axList = axList.flatten()\n",
    "#fig.set_size_inches(15, 15)\n",
    "\n",
    "#axList[-1].axis('off')\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g');\n",
    "plt.title('Confusion matrix of the classifier')    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "summaryfile = 'ModelsFitness.txt'\n",
    "nbdir = os.getcwd()\n",
    "fsummary = open(f'{nbdir}\\\\{summaryfile}',\"a\") \n",
    "fsummary.write('Wine Quality Analysis with Support Vector Machine\\tProcessing (sec):{:.4f}\\tAccuracy: {:.4f}\\tF1-Score: {:.4f}\\r\\n'.format(proctime,accuracy,fscore))\n",
    "fsummary.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}