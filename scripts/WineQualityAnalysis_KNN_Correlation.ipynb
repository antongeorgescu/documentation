{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read red wine set of observations\n",
    "data_red = pd.read_csv(\"C:/Users/ag4488/Documents/Python/svm-classification-with-pytorch/data/winequality-red.csv\",sep=',')\n",
    "data_red['color'] = 1 #redwine\n",
    "\n",
    "print(data_red.shape)\n",
    "\n",
    "# read white wine set of observations\n",
    "data_white = pd.read_csv(\"C:/Users/ag4488/Documents/Python/svm-classification-with-pytorch/data/winequality-white.csv\",sep=',')\n",
    "data_white['color'] = 0 #whitewine\n",
    "\n",
    "print(data_white.shape)\n",
    "\n",
    "# merge the two sets in one\n",
    "data = data_red.merge(data_white, how='outer')\n",
    "fields = list(data.columns)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the counts of all quality levels\n",
    "print(\"All 'quality level' counts\")\n",
    "print(data[\"quality\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the \"quality histograms\" above, we will drop the ratings with low counts (we will keep only 5,6,7)\n",
    "data = data.drop(data[data.quality == 9].index)\n",
    "data = data.drop(data[data.quality == 8].index)\n",
    "data = data.drop(data[data.quality == 3].index)\n",
    "data = data.drop(data[data.quality == 4].index)\n",
    "\n",
    "# show the counts of selected quality levels\n",
    "print(\"Selected 'quality level' counts\")\n",
    "print(data[\"quality\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set in two: 1) color+features (observations)  2) quality (actuals)\n",
    "\n",
    "# select the outcomes\n",
    "y = data['quality']\n",
    "\n",
    "data = data.drop(columns=['quality'])\n",
    "\n",
    "# select the rows (observations)\n",
    "fields = list(data.columns)\n",
    "X = data[fields]\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pearson correlation was used to identify which features correlate with wine quality. It looks as if higher the alcohol content the higher the quality. Lower density and volatile acidity also correlated with better quality as seen in the pairwise correlation chart the chart below. Only the top 5 correlated features were carried over to the SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data[fields].corrwith(y)\n",
    "correlations.sort_values(inplace=True)\n",
    "\n",
    "# the following fields are the 5 retained as having the highest correlations to wine quality\n",
    "fields = correlations.map(abs).sort_values().iloc[-5:].index\n",
    "print(fields) #prints the top two abs correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# The figure below shows Pearson Pairwise correlation of features to wine quality.\n",
    "# Looks like alcohol and density are the most correlated with quality\n",
    "ax = correlations.plot(kind='bar')\n",
    "ax.set(ylim=[-1, 1], ylabel='pearson correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run now K_Nearest Neighbour algorithm (KNN) to create a \"prediction model\"\n",
    "KNN converges faster when features are scaled. If the model is senstive to magnitudes its generally a good idea to scale so one feature doesnâ€™t get more influence than the other(in terms of scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DO_STANDARDSCALER = True\n",
    "X = data[fields]\n",
    "scaler = None\n",
    "\n",
    "if DO_STANDARDSCALER:\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    X = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\n",
    "    print(X.columns) #scaled columns\n",
    "\n",
    "    print(scaler.mean_)\n",
    "    print(scaler.scale_)\n",
    "\n",
    "else:\n",
    "    scaler = MinMaxScaler().fit(X)\n",
    "    print(scaler.data_max_)\n",
    "    print(scaler.data_min_)\n",
    "\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    X = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\n",
    "    print(X.columns) #scaled columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we will split the data in training (70%) and testing (30%) whihc is the usual ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate KNN learning model (k=15)\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "# predict the wine rankings for the test data set\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(print('predict\\tactual\\tcolor_scaled,','chlorides_scaled,','volatile acidity_scaled,','density_scaled,','alcohol_scaled'))\n",
    "i=0\n",
    "for index,row in X_test.iterrows():\n",
    "    print(f\"{list(y_pred)[i]}\\t{list(y_test)[i]}\\t\",f\"{row['color_scaled']}, {row['chlorides_scaled']},{row['volatile acidity_scaled']}, {row['density_scaled']},{row['alcohol_scaled']}\")\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Calculate the accuracy of prediction\n",
    "metrics = list()\n",
    "cm = dict()\n",
    "\n",
    "# Precision, recall, f-score from the multi-class support function\n",
    "precision, recall, fscore, _ = score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "metrics.append(pd.Series({'precision':precision, 'recall':recall, \n",
    "                          'fscore':fscore, 'accuracy':accuracy}, \n",
    "                         name='Model'))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Last, the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='.2g');\n",
    "plt.title('Confusion matrix of the KNN classifier (use Correlation)')    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# another way to calculate the prediction accuracy by using a KNN built-in method\n",
    "mean_accuracy = knn.score(X_test,y_test)\n",
    "print(mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try now to get the quality prediction for a new wine that comes with the 5 sets of parameters:\n",
    "'color', 'chlorides', 'volatile acidity', 'density', 'alcohol'\n",
    "\n",
    "Examples:\n",
    "    red wine:          [1,0.114,0.78,0.9545,8.5]\n",
    "    white wine:        [0,0.019,0.23,0.9745,9.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = [[1,0.114,0.78,0.9545,7],[0,0.032,0.23,0.9945,16.2]]\n",
    "dfX=pd.DataFrame(X0)\n",
    "\n",
    "print(\"===Wines (new data)=====================================================\")\n",
    "dfX.columns = ['color', 'chlorides', 'volatile acidity', 'density', 'alcohol']\n",
    "dfX.index = ['red_wine_0','white_wine_0']\n",
    "print(dfX)\n",
    "print(\"\\n===Predicted Quality====================================================\")\n",
    "\n",
    "inxs = dfX.index\n",
    "\n",
    "dfX = scaler.transform(dfX)\n",
    "y0_pred = knn.predict(dfX)\n",
    "print(\"Predicted quality:\")\n",
    "print(f\"{inxs[0]}:\\t{y0_pred[0]}\")\n",
    "print(f\"{inxs[1]}:\\t{y0_pred[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
